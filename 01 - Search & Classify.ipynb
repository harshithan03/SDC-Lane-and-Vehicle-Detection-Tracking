{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "from features import *\n",
    "%matplotlib inline\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# uncomment if you want to run find_cars() for still images outside of track_vehicles()\n",
    "\n",
    "# model_pickle = pickle.load(open('00-training.pkl', 'rb'))\n",
    "# svc = model_pickle['svc']\n",
    "# X_scaler = model_pickle['scaler']\n",
    "# orient = model_pickle['orient']\n",
    "# pix_per_cell = model_pickle['pix_per_cell'] \n",
    "# cell_per_block = model_pickle['cell_per_block']\n",
    "# spatial_size = model_pickle['spatial_size']\n",
    "# hist_bins = model_pickle['hist_bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    box_list = []\n",
    "    \n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        # could be [0,255] or [0,1] depending how the file was read in\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (255,0,0), 6)\n",
    "        \n",
    "        box_list.append(bbox)\n",
    "\n",
    "    return img, box_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    #draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    bboxes = []\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                bboxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                \n",
    "                #if you want to draw hog subsampling boxes\n",
    "                #cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)\n",
    "    \n",
    "    #add up heat overlap \n",
    "    heatmap = add_heat(heat, bboxes)\n",
    "                \n",
    "    return heatmap, bboxes #, draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def track_vehicles(img):\n",
    "    \n",
    "    global draw_img_prev, bbox_list_prev, labels_prev, heatmap_sum\n",
    "    global first_frame, frame_count\n",
    "    \n",
    "    model_pickle = pickle.load(open('00-training.pkl', 'rb'))\n",
    "    svc = model_pickle['svc']\n",
    "    X_scaler = model_pickle['scaler']\n",
    "    orient = model_pickle['orient']\n",
    "    pix_per_cell = model_pickle['pix_per_cell'] \n",
    "    cell_per_block = model_pickle['cell_per_block']\n",
    "    spatial_size = model_pickle['spatial_size']\n",
    "    hist_bins = model_pickle['hist_bins']\n",
    "    \n",
    "    #this could be changed relative to image size\n",
    "    ystart = 400\n",
    "    ystop = 420\n",
    "    \n",
    "    if first_frame:\n",
    "        \n",
    "        #initialize the running average heatmap\n",
    "        heatmap_sum = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "        \n",
    "        for scale in (1.0,1.5,2.0):\n",
    "            \n",
    "            #as the image scale gets bigger, the ROI needs to extend\n",
    "            ystop = ystop + 75\n",
    "\n",
    "            heatmap, bboxes = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, \n",
    "                                        pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "            #sum up heatmap for all scales\n",
    "            heatmap_sum = np.add(heatmap_sum,heatmap)\n",
    "        \n",
    "        heatmap = apply_threshold(heatmap_sum, 2)\n",
    "        heatmap = np.clip(heatmap, 0, 1)\n",
    "        labels = label(heatmap)\n",
    "        draw_img, bbox_list = draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "        draw_img_prev = draw_img\n",
    "        bbox_list_prev = bbox_list\n",
    "        labels_prev = labels\n",
    "\n",
    "        first_frame = False\n",
    "    \n",
    "        return draw_img\n",
    "    \n",
    "    if frame_count <= 2:\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        #reset ROI\n",
    "        ystop = 420\n",
    "        \n",
    "        for scale in (1.0,1.5,2.0):\n",
    "\n",
    "            ystop = ystop + 75\n",
    "            heatmap, bboxes = find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                                            orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "            heatmap_sum = np.add(heatmap_sum,heatmap)\n",
    "            draw_img = np.copy(img)\n",
    "        \n",
    "        #draw old boxes\n",
    "        for unique_car in range(1, labels_prev[1]+1):\n",
    "            draw_img = cv2.rectangle(draw_img, bbox_list_prev[unique_car-1][0],\n",
    "                                     bbox_list_prev[unique_car-1][1], (255,0,0), 6)\n",
    "        return draw_img\n",
    "    \n",
    "    heatmap = apply_threshold(heatmap_sum,2)\n",
    "    heatmap = np.clip(heatmap, 0, 255)\n",
    "    labels = label(heatmap)   \n",
    "    draw_img, bbox_list = draw_labeled_bboxes(np.copy(img), labels)   \n",
    "    \n",
    "    draw_img_prev = draw_img\n",
    "    bbox_list_prev = bbox_list\n",
    "    labels_prev = labels\n",
    "    \n",
    "    #reset heatmap sum and frame_count\n",
    "    heatmap_sum = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    frame_count = 0\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.preprocessing.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m frame_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m first_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m draw \u001b[38;5;241m=\u001b[39m \u001b[43mtrack_vehicles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(draw);\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mtrack_vehicles\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m draw_img_prev, bbox_list_prev, labels_prev, heatmap_sum\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m first_frame, frame_count\n\u001b[1;32m----> 6\u001b[0m model_pickle \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m00-training.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m svc \u001b[38;5;241m=\u001b[39m model_pickle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m X_scaler \u001b[38;5;241m=\u001b[39m model_pickle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.preprocessing.data'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "images = glob.glob('test_images/*jpg')\n",
    "for index, image in enumerate(images):\n",
    "    img = mpimg.imread(image)\n",
    "    global first_frame, frame_count\n",
    "    frame_count = 0\n",
    "    first_frame = True\n",
    "    draw = track_vehicles(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(draw);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output_images{}'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MoviePy error: the file processed-project_video.mp4 could not be found!\nPlease check that you entered the correct path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m first_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      5\u001b[0m project_video_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_pipeline.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m clip2 \u001b[38;5;241m=\u001b[39m \u001b[43mVideoFileClip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed-project_video.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m project_video_clip \u001b[38;5;241m=\u001b[39m clip2\u001b[38;5;241m.\u001b[39mfl_image(track_vehicles)\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_video_clip.write_videofile(project_video_output, audio=False, verbose=False)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Make a reader\u001b[39;00m\n\u001b[0;32m     87\u001b[0m pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m \u001b[43mFFMPEG_VideoReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpix_fmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpix_fmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mresize_algo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mduration\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m infos \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_parse_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_duration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfps_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_fps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:270\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    268\u001b[0m lines \u001b[38;5;241m=\u001b[39m infos\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoviePy error: the file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m could not be found!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that you entered the correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m%\u001b[39mfilename)\n\u001b[0;32m    274\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# get duration (in seconds)\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: MoviePy error: the file processed-project_video.mp4 could not be found!\nPlease check that you entered the correct path."
     ]
    }
   ],
   "source": [
    "global first_frame, frame_count\n",
    "frame_count = 0\n",
    "first_frame = True\n",
    "\n",
    "project_video_output = 'combined_pipeline.mp4'\n",
    "clip2 = VideoFileClip('processed-project_video.mp4')\n",
    "\n",
    "project_video_clip = clip2.fl_image(track_vehicles)\n",
    "%time project_video_clip.write_videofile(project_video_output, audio=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"combined_pipeline.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = 'combined_pipeline.mp4'\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# NEXT STEPS\n",
    "# How fast does this run without editing the images at all, just returning calculations? Does it run in realtime? \n",
    "# Can my phone process this in realtime?\n",
    "# \n",
    "# YOLO and SSD on computer AND/OR Android APK "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
